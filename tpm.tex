\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage[T1]{fontenc}
\usepackage[top=25mm, bottom=25mm, left=35mm, right=25mm]{geometry}
\usepackage{array}
\usepackage{verbatim}
\usepackage{csquotes}
\usepackage{graphicx}
\usepackage{fullpage}
\usepackage{hyperref}
\usepackage[usenames,dvipsnames]{color}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{fix-cm}
\usepackage{float}
\usepackage{biblatex}
\usepackage{setspace}
\usepackage[table]{xcolor}
\usepackage{booktabs}
\usepackage{listings}
\definecolor{light-gray}{gray}{0.75}
\definecolor{ulbleu}{rgb}{0, .3, .57}
\hypersetup{
  pdftitle={Interrogation de bases de données via un langage naturel – Application au domaine de l’édition. Travail Préparatoire au Mémoire},
  pdfauthor={Contzen Laurent},
  colorlinks=true,
  linkcolor=ulbleu,
  urlcolor=ulbleu,
  citecolor=ulbleu,
  linktoc=all
}
\DeclareCiteCommand{\titleandsubtitle}
                   {\boolfalse{citetracker}%
                     \boolfalse{pagetracker}%
                     \usebibmacro{prenote}}
                   {\indexfield{indextitle}%
                     \printtext[citetitle]{%
                       \printfield[noformat]{title}%
                       \iffieldundef{subtitle}{}{\subtitlepunct}%
                       \printfield[noformat]{subtitle}}}%
                   {\multicitedelim}
                   {\usebibmacro{postnote}}
\DeclareCiteCommand*{\citeauthor}
                    {\defcounter{maxnames}{99}%
                      \defcounter{minnames}{99}%
                      \defcounter{uniquename}{2}%
                      \boolfalse{citetracker}%
                      \boolfalse{pagetracker}%
                      \usebibmacro{prenote}}
                    {\ifciteindex{\indexnames{labelname}}{}%
                      \printnames{labelname}}
                    {\multicitedelim}
                    {\usebibmacro{postnote}}
\bibliography{tpm}
\defbibheading{bibliography}{}
\newcommand{\fliptable}{$( $\raisebox{0.75em}{\oval(10,10)[r b] }$\;   ^{\circ} \square ^{\circ} ) $\raisebox{0.75em}{\oval(10,10)[r b] }$ \; \smallfrown$ \raisebox{0.25em}{$\bot$}{\bf --}\raisebox{0.25em}{$\bot$}}
\newcommand{\prettycite}[1]{\citeauthor*{#1} - \titleandsubtitle{#1} \cite{#1}}
\title{Travail Préparatoire au Mémoire}
\date{Juin 2012}
\author{Contzen Laurent (lcontzen@ulb.ac.be)}
\onehalfspacing
\begin{document}

\begin{titlepage}
  \singlespacing
  \begin{center}
    \huge{\textsc{Université Libre de Bruxelles}}\\
    \huge{Faculté de Philosophie et Lettres}
  \end{center}
  \vfill
  \begin{center}
    \Huge{\textbf{Interrogation de bases de données via un langage naturel}}\\
    \LARGE{Application au domaine de l'édition}
  \end{center}
  \vfill
  \begin{tabular}{b{5.5cm}b{7.5cm}}
    Laurent \textsc{Contzen} & Travail préparatoire au mémoire qui sera présenté sous la direction de M. Anthony \textsc{Cleve} en vue de l'obtention du titre de Maître en Sciences et Technologies de \mbox{l'Information} et de la Communication\\
  \end{tabular}
  \vfill
  \begin{center}
    Année académique 2011--2012
  \end{center}
\end{titlepage}

\tableofcontents
\newpage

\section{Introduction}
L'évolution des technologies depuis plusieurs décennies, et l'avènement du Web en particulier, ont permis l'enregistrement et la mise à disposition d'une quantité colossale d'informations.
L'expression \textit{big data} est utilisée pour désigner ces ensembles de données d'une taille telle que leur traitement par les moyens classique devient presque impossible.
Ce phénomène impose une nouvelle réflexion à propos de tout ce qui est lié à ces données, telles que les méthodes de traitement de données, de recherche d'informations, de stockage de ces données, et bien d'autres.
La production toujours plus importante de contenu par des utilisateurs ainsi que le succès toujours croissant des réseaux sociaux laissent présager que ce phénomène va encore s'intensifier dans les années à venir, créant toujours plus d'informations à manipuler le plus rapidement et efficacement possible.\\

Ces informations sont, depuis la création des systèmes d'information, organisées et enregistrées dans des bases de données.
Il existe différents paradigmes dans ce domaine, mais le modèle le plus utilisé actuellement est le modèle relationnel.
Le langage de référence afin d'interagir avec une base de données suivant ce modèle est le SQL\footnote{Structured Query Language}.
Ce langage est extrêmement puissant mais impose beaucoup de rigueur ainsi qu'une connaissance complète de la structure de la base de données avec laquelle l'on désire interférer.
Cette complexité, couplée au fait que le SQL permet aussi de modifier les données, a amené à la création de dispositifs intermédiaires permettant de rechercher des informations.
Ces dispositifs nécessitent fréquemment l'utilisation d'un langage contrôlé au vocabulaire précis ou la structuration très précise de la requête à l'aide d'opérateurs booléens. 
Ceci n'est pas à la portée de tout un chacun sans formation préalable et un utilisateur non-initié confronté à ces obligations se retrouvera désorienté et ne parviendra pas à obtenir l'information qu'il recherche. 
Une fois la requête correctement formulée, il faut ensuite réussir à comprendre les résultats renvoyés par le système d'information.
Cette étape dans l'obtention d'une information peut parfois se révéler tout aussi compliquée que la précédente.
Effectuer une recherche dans un système d'information contenant une grande quantité de données est donc souvent une opération complexe lorsqu'un résultat précis et compréhensible est désiré.
Avoir la possibilité de dialoguer de manière simplifiée avec un système d'information permettrait à un large public non-informaticien d'accéder aux informations qu'il contient. \\

Nous sommes donc en présence d'une quantité massive d'informations pour laquelle nous avons besoin d'un support d'accès différent du support de prédilection actuel, le SQL. 
Le langage naturel apparaît ici comme un support de choix.
En effet, un utilisateur non-informaticien mais expert dans le domaine à propos duquel il recherche une information saura exprimer clairement sa question de manière aisée et transparente, sans devoir apprendre un autre langage. 
Il est évident que ceci est applicable aussi bien pour la recherche d'informations que pour la manipulation de données (insertion, suppression, modification), mais les méthodologies pour ces différentes opérations différeront largement d'une opération à une autre.
C'est pourquoi un choix fut nécessaire et nous nous concentrerons sur la recherche d'informations car cette opération est la plus utile au plus grand nombre d'utilisateurs. \\

A l'instar du choix de l'opération offerte à l'utilisateur, un choix concernant la langue doit être fait.
En effet, les langues existant actuellement sont fondamentalement différentes à plusieurs points de vues (orthographe, syntaxe, ...) et une question posée dans une langue ne pourra pas être automatique analysée de la même manière lorsque posée dans une autre langue.
L'essentiel des recherches en ingénierie linguistique étant faites en utilisant l'anglais comme langage naturel, nous avons décidé d'utiliser l'anglais comme langue dans laquelle les utilisateurs dialogueront avec le système.
Ce choix est justifié aussi par la quantité d'informations disponibles en anglais sur Internet pour peupler la base de données. \\

Afin de rester dans un cadre ciblé et précis, le domaine d'application de l'édition, et plus particulièrement des films, a été choisi.
Ce choix est motivé par plusieurs faits.
Tout d'abord, les informations disponibles sur le sujet sont nombreuses tout en restant dans un cadre précis et structuré.
Ensuite, ce domaine est connu d'un grand nombre, ce qui permettra de trouver aisément un panel d'utilisateurs pour la phase de tests.
Enfin, du fait de mon intérêt personnel pour ce sujet, des connaissances sont déjà acquises.
Il ne s'agira donc pas de découvrir la matière, mais bien de l'approfondir, ce qui, en termes de motivation et de compétences, représente un avantage non négligeable. \\

L'objectif du mémoire faisant ici l'objet de ce travail préparatoire est donc d'implémenter un logiciel ayant pour but de permettre à un utilisateur de poser une question en langage naturel ou dans un langage possédant une syntaxe et une structure beaucoup moins contraignantes et beaucoup plus intuitives que celles des langages contrôlés actuellement existants et d'obtenir, s'il en existe une, une réponse en langage naturel.
Ceci a pour volonté d'essayer de déterminer s'il est possible de dialoguer de manière conceptuelle avec une base de données, sous les hypothèses et choix qui seront faits tout au long de ce mémoire. \\

Ce mémoire permettra aussi une réflexion sur les interactions humains-ordinateurs.
Depuis les débuts de l'informatique des outils ont étés successivement créés en suivant les évolution des technologies et des recherches en traitement de langages naturels afin de permettre à un utilisateur de dialoguer le plus naturellement possible avec un ordinateur.
Le premier exemple connu de tel système fût le programme Eliza\footfullcite{weizenbaum1966eliza} développé par J. Weizenbaum de 1946 à 1966 offrant une simulation de psychothérapeute.
De nombreux outils similaires et de plus en plus évolués ont été développés au fil du temps, mais la question de l'usabilité pour un utilisateur lambda se pose toujours.
Bien que le Test de Turing\footfullcite{turing1950computing} permette de déterminer si un système émule parfaitement un comportement humain dans une discussion, il est encore nécessaire de définir si un utilisateur est à l'aise à l'idée de dialoguer naturellement avec un ordinateur.
Il sera donc intéressant de prendre ceci en compte lors de la phase de tests afin de tenter de déterminer si les utilisateurs seront satisfaits de la solution mise en place. \\

Enfin, ce mémoire sera pluridisciplinaire et me permettra d'appliquer et d'approfondir des compétences acquises dans différents cours de mon cursus, principalement les bases de données, l'ingénierie linguistique et la programmation. 
\newpage
\section{Table des matières commentée du mémoire}
Bien que sujette à modifications lors de la réalisation du mémoire, cette table des matières donne un aperçu de la manière dont le travail sera organisé.
\subsection{Introduction}
L'introduction abordera la problématique à laquelle ce mémoire tentera d'apporter une solution.
Elle sera axée sur une présentation claire et succincte des tenants et aboutissants du projet et présentera les objectifs du mémoire ainsi que les hypothèses de travail qui seront posées.
La portée du mémoire sera aussi clairement définie.
\subsection{État de l'art}
Le sujet traité par ce mémoire a déjà été abordé par le passé dans diverses recherches.
Cet état de l'art résumera les solutions existantes ainsi que les recherches menées en la matière.
De par le caractère pluridisciplinaire de ce travail, cet état de l'art sera structuré en plusieurs parties afin d'aborder clairement tous les domaines concernés.
La partie ingénierie linguiste sera orientée vers l'extraction d'informations et le ``question answering''.
La partie bases de données quand à elle sera spécifiquement dirigée vers la conception de bases de données ainsi que les rapports entre schéma conceptuel et schéma relationnel.
Enfin, le coeur de ce mémoire étant l'accès à une base de données via un langage naturel, il sera crucial de considérer les recherches déjà faites en la matière.
\subsection{Modélisation du domaine d'application choisi}
La première étape de la conception du logiciel sera de modéliser le domaine d'application afin de créer un schéma conceptuel à partir duquel il sera possible de contraindre le langage naturel sélectionné. Les différents types de requêtes possibles seront alors dérivés de ce schéma qui sera composé de concepts, de propriétés et de relations entre ces concepts. \\

Le schéma, et donc les possibilités de requêtes, sera d'abord simplifié au possible puis enrichi incrémentalement, ce qui enrichira le jeu de questions possibles.
Ceci permettra de définir les limites dont nous pourrons nous approcher, autant au niveau technique qu'au niveau de discussion avec une machine.
\subsection{Étude des possibilités de jeux de requêtes}
Il sera nécessaire de faire des choix sur les possibilités offertes, autant du point de vue vocabulaire que du point de vue syntaxe.
Ces possibilités seront donc définies par le schéma conceptuel.
Il pourra être intéressant de proposer deux méthodes d'interrogation de la base de données.
La première utiliserait un formalisme imposé à l'utilisateur balisant sa requête.
Ce formalisme devra bien entendu rester extrêmement intuitif pour l'utilisateur afin de ne pas retomber dans les problèmes des systèmes de recherche d'informations classiques.
Il pourra être de la forme \verb@actor=<nom>@. 
L'autre méthode serait un langage beaucoup plus libre, et donc dont l'extraction des données utiles sera plus complexe. 
La mise en place de ces deux méthodes permettra de comparer les résultats de qualité de réponses renvoyées à l'utilisateur selon son degré de liberté dans les questions. \\

Il sera nécessaire aussi de bien définir les types d'entités que l'on désirera reconnaître dans les questions.
Les noms de films, de personnes et années semblent être une bonne base. 
\subsection{Construction de la base de données et de son contenu}
Le manière dont les données seront enregistrées dans la base de données ainsi que les données en elles-mêmes joueront bien évidement un rôle crucial dans la qualité des résultats que le logiciel fournira.
\subsubsection{Conception du schéma relationnel de la base de données}
Une fois le schéma conceptuel et les possibilités de jeux de requêtes clairement définis, il sera possible et nécessaire de concevoir le schéma relationnel de la base de données en fonction de ce schéma conceptuel afin de permettre une recherche de résultats la plus performante et cohérente possible.
L'architecture de la base de données fera donc l'objet d'une étude réfléchie et justifiée.
\subsubsection{Collecte et insertion de données dans la base de données}
Afin de pouvoir évaluer la qualité des résultats renvoyés par le logiciel, il faudra peupler celle ci avec des données de qualité concernant le domaine d'application.
L'Internet Movie DataBase\footnote{\url{http://imdb.com}} offre une possibilité de récupération de données structurées.
Ceci pourra être une bonne source de données tout en gardant à l'esprit que les sites collaboratifs tels que celui ci ne peuvent être considérés comme parfaits. \\

Une fois les données collectées, il faudra les insérer dans la base de données de manière automatisée et cohérente avec l'architecture de celle-ci.
\subsection{Des requêtes et réponses}
\subsubsection{Conception de l'analyse des requêtes}
Point essentiel pour la qualité des résultats, les requêtes des utilisateurs devront être correctement étudiées afin d'extraire toutes les informations utiles et uniquement elles.
Diverses techniques d'ingénierie linguistique existent à cette fin, il faudra donc sélectionner la plus appropriée. 
\subsubsection{Conception de la recherche de réponse}
Une fois les informations utiles extraites de la question, il faudra pouvoir obtenir la réponse dans les informations contenues dans la base de données.
Cette recherche devra elle aussi être soigneusement réfléchie afin de garantir une qualité de résultats la plus élevée possible.
\subsubsection{Conception de la méthode de formulation de réponses}
Enfin, il faudra être capable de renvoyer une réponse claire et compréhensible à l'utilisateur afin d'éviter qu'il ne se méprenne sur sa validité.
Il sera toutefois important de ne pas négliger la réflexion sur la structuration de la réponse.
Dans certains cas, une réponse structurée sous forme de liste ou de résultat direct non formulé sous forme de phrase pourra mieux convenir à l'utilisateur.
\subsection{Implémentation}
L'implémentation du logiciel sera l'élément central de ce mémoire afin de concrétiser toute l'étude théorique précédemment réalisée.
Elle sera à priori réalisée en utilisant au moins deux langages de programmation différents.
Pour tout ce qui est lié à l'ingénierie linguistique le Python est actuellement le langage de référence dans la communauté de développeurs d'outils de traitement de langages naturels.
Le toolkit NLTK\footnote{\url{http://www.nltk.org/}} jouit d'une excellente réputation et fournit énormément d'outils facilitant le développement.
Il a toutefois diverses faiblesses telles que sa lourdeur et sa difficulté d'utilisation dans un environnement non totalement contrôlé.
De plus, la plupart des fonctionnalités fournies par NLTK ne sont pas très compliquées à ré-implémenter soi-même.
Le choix de l'utilisation ou non de ce toolkit sera donc à réfléchir soigneusement. \\

Il pourra être intéressant d'utiliser le service OpenCalais\footnote{\url{http://viewer.opencalais.com/}} afin de vérifier les résultats de l'analyse des requêtes de l'implémentation ici effectuée.
Ce service n'étant, contrairement à ce que son nom laisserait présager, pas open-source, son utilisation sera limitée à cette vérification et il ne sera pas possible d'utiliser les résultats de leurs recherches dans la conception de notre analyse des requêtes. \\

Le reste de l'implémentation sera à priori réalisé à l'aide du langage Java et utilisera l'outil d'architectures de données DB-Main\footnote{\url{http://www.db-main.eu}}.
\subsection{Évaluation des résultats}
Lorsque le logiciel sera implémenté et fonctionnel, une phase de test sera effectuée afin de déterminer si les résultats renvoyés aux utilisateurs sont pertinents par rapport aux attentes et répondent clairement aux requêtes.
\subsubsection{Méthode}
La méthode de tests du logiciel sera précautionneusement conçue afin de refléter au mieux la pertinence générale des réponses. Plusieurs éléments seront mesurés. Tout d'abord, la validité des résultats renvoyés sera évidement mesurée, tout comme la couverture du domaine par le jeu de requêtes. Ensuite, une comparaison avec les résultats des requêtes équivalentes formulées directement en SQL sera effectuée. Comme défini précédemment, l'usabilité du logiciel sera l'objet d'une étude attentive. Enfin les performances techniques du systèmes seront évaluées, ce qui permettra par exemple de déterminer si les technologies choisies ainsi que les méthodes d'implémentation étaient pertinentes.
Il est important de souligner que la langue anglaise ayant été choisie, il est évident qu'il faudra s'assurer que tous les utilisateurs du panel de testeurs maîtrisent cette langue. \\

La méthode de tests sera donc établie afin de mesurer ces différents paramètres.
\subsubsection{Résultats}
Ces résultats de la phase de tests seront naturellement d'une importance cruciale : ils permettront de déterminer si les choix effectués tout au long du mémoire et l'implémentation déployée ont permis de mettre en place une solution répondant positivement à la question de recherche.
\subsection{Conclusion}
Chapitre final du mémoire, la conclusion sera une critique de l'approche suivie ainsi que du choix des hypothèses de départ et de l'évolution de celles-ci.
En véritable réponse à l'introduction, nous rappellerons la démarche et verrons si les objectifs de base sont atteints, en justifiant soigneusement toute réponse positive ou négative.
Les forces et faiblesses de la démarche établie seront exposées afin de déterminer ce qui pourrait être modifié à l'avenir.
\newpage
\section{Bibliographie commentée}
La bibliographie présentée ici est forcément incomplète par rapport à celle que contiendra ce mémoire.
Elle donne toutefois déjà un appercu des différents domaines qui seront présentés et des sources qui seront utilisées.
Afin d'enrichir cette bibliographie, j'effectuerai des recherches bibliographiques approfondies, autant dans les bases de données documentaires auxquelles l'Université nous permet l'accès que dans d'autres telles que l'ACM.
Je n'hésiterai pas non plus à entrer en contact avec des personnes ayant déjà fait des recherches liées au sujet de ce mémoire en cas de besoin d'informations complémentaires, aisni qu'à consulter les notes de diverses conférences telles que ER, VLDB et NLP Conferences. \\
Les éléments bibliographiques repris ci-dessous sont ici organisés par thèmes afin de simplifier les commentaires et d'éviter une redondance inutiles de ceux ci. La bibliographie complète et structurée est disponible dans la \autoref{sec:bibliography}.
\subsection{Bases de données}
Comme énoncé précédemment, une bonne architecture de la base de données sera nécessaire à la bonne réalisation du mémoire. \\ 
\noindent\textbf{Références :}
\begin{itemize}
  \item \prettycite{hainaut2012bases} \\
    Livre de référence pour le cours de bases de données de notre cursus.
  \item \prettycite{date2009sql} \\
    Livre axé sur les bonnes pratiques en SQL.
\end{itemize}
\subsection{Ingénierie linguistique}
L'ingénierie linguistique est un domaine vaste dont plusieurs sous domaines nous intéresseront. 
\subsubsection*{Général}
\noindent\textbf{Références :}
\begin{itemize}
  \item \prettycite{jurafsky2009speech} \\
    Livre de référence pour le cours d'ingénierie linguistique de notre cursus.
  \item \prettycite{katz1988exploiting}
\end{itemize}
\subsubsection*{Information Extraction}
L'extraction d'informations permettra, comme le nom de ce domaine le laisse présager, d'extraire les informations utiles des requêtes des utilisateurs. \\
\noindent\textbf{Références :}
\begin{itemize}
  \item \prettycite{soderland1999learning} \\
    Les données que nous allons traiter seront semi-structurées, cet article présente donc un intérêt non négligeable.
  \item \prettycite{appelt1999introduction}
  \item \prettycite{cardie1997empirical}
  \item \prettycite{huffman1996learning}
\end{itemize}
\subsubsection*{Question answering}
La formulation des réponses récupérées dans la base de données sera elle aussi l'objet d'une consultation et d'une analyse des recherches déjà effectuées dans ce domaine. \\
\noindent\textbf{Références :}
\begin{itemize}
  \item \prettycite{katz2006natural}
  \item \prettycite{katz2005external}
  \item \prettycite{lin2003role}
  \item \prettycite{ravichandran2002learning}
  \item \prettycite{reder1987strategy}
\end{itemize}
\subsection{Interactions avec des bases de données à l'aide de langage naturel}
Coeur du sujet de ce mémoire, le thème des interactions avec des bases de données à l'aide de langage naturel a déjà été l'objet de recherches variées qu'il sera utile de consulter. \\
\noindent\textbf{Références :}
\begin{itemize}
\item \prettycite{Samsonova03072003}
\item \prettycite{Mazlack:1980:EBM:636669.636681}
\item \prettycite{owda2007conversation}
\item \prettycite{waltz1978english}
\item \prettycite{sneiders2002automated}
\item \prettycite{liu2006effective}
\item \prettycite{frank2007question} 
\item \prettycite{li2006constructing}
\item \prettycite{androutsopoulos1995natural}
\end{itemize}
\subsection{Programmation}
L'aspect programmation du mémoire est d'une importance capitale afin de pouvoir obtenir des résultats concrets pouvant être analysés. Les langages de programmation allant être utilisés étant le Python et le Java, nous utiliserons diverses références concernant ces deux langages précis. Il est à noter que ces références seront plus utiles afin de mettre en pratique divers concepts que pour la recherche sur le sujet en lui même. \\
\noindent\textbf{Références :}
\begin{itemize}
  \item \prettycite{learnpythonthehardway}
  \item \prettycite{lutz2011programming}
  \item \prettycite{lutz2009python}
  \item \prettycite{nlpwithpython}
  \item \prettycite{sierra2005head}
  \item \prettycite{deitel2012java}
\end{itemize}


\newpage
\section{Plan de travail}
\begin{tabular}{p{4cm} p{9cm}}
  \toprule
  \large{Échéances} & \large{Étapes devant être complétées} \\
  \midrule
  \large{Novembre 2012} & \begin{itemize}
    \item État de l'art et analyse de l'existant
    \item Définition des possibilités de requêtes
    \item Conception théorique de la base de données en accord avec ces possibilités de requêtes
    \item Étude de la collecte et de l'insertion des données dans la base de données
  \end{itemize}
  \\
  \large{Mars 2013} & \begin{itemize}
    \item Analyse des requêtes
    \item Conception de la recherche de la meilleure réponse
    \item Conception de la méthode de formulation des réponses
    \item Création de la base de données
    \item Collecte et insertion des données
    \item Implémentation en cours
  \end{itemize}
  \\
  \large{Avril 2013} & \begin{itemize}
    \item Implémentation terminée
    \item Conception de la phase de tests
    \item Phase de tests
    \item Analyse des résultats de la phase de tests
  \end{itemize}
  \\
  \large{15 Mai 2012} & Remise du mémoire. \\
  \bottomrule
\end{tabular}

%% \newpage
%% \section{Notes variées}
%% Cette section ne sera pas dans le travail final mais la plupart des informations contenues ici se retrouveront probablement autre part dans le travail.
%% \subsection{Partie Ingénierie Linguistique}
%% Après un rendez vous avec Max De Wilde afin de préparer cette partie, nous sommes arrivés aux conclusions suivantes :
%% \begin{itemize}
%%   \item IMDB offre la possibilité de télécharger le contenu de leur base de données en plain text et il existe plusieurs sites offrant une API permettant d'interagir avec ces données. Se limiter aux films dans un premier temps comme domaine d'application semble déjà conséquent et suffisant.
%%   \item Il y a pas mal d'informations interessantes sur le sujet ou pouvant être liées au sujet dans le cours en ligne actuellement donné par l'université de stanford (NLP class), c'est une bonne source.
%%   \item On partirait sur deux méthodes d'interrogation de la base de données pour l'utilisateur. La première utiliserait un formalisme que l'utilisateur devrait respecter (par exemple actor=''<nom>'') alors que la seconde serait plus libre. Il sera alors possible et interessant de comparer les résultats des deux méthodes. Le formalisme serait bien évidement plus intuitif que les techniques standard d'interrogation de bases de données ou de recherche documentaire actuelles.
%%   \item Il faudra bien définir les types d'entités que l'on désire reconnaître dans les questions. Partir sur un base de Noms de films, noms de personnes, et années parait être un bon début.
%%   \item Il faudrait réussir à différencier les acteurs, réalisateurs, personnages, etc.
%%   \item Le formalisme permettra clairement une granularité de recherche plus précise.
%%   \item Il faudra définir un ordre d'application dans le mapping.
%%   \item Il est envisageable d'utiliser l'API d'OpenCalais afin de vérifier certains résultats. Malheureusement contrairement au nom ce service n'est pas open-source.
%%   \item Python est le langage de choix à utiliser pour cette partie du mémoire. Le framework NLTK est toutefois parfois fort lourd, surtout pour ce qui sera à faire. Il faudra donc bien réfléchir s'il est nécéssaire de l'utiliser ou s'il est possible de faire le nécéssaire sans.
%% \end{itemize}

%% \subsection{Description du projet de mémoire}
%% Implémentation d’un logiciel ayant pour but de permettre  à un utilisateur de poser une question en langage naturel et d’obtenir, s’il en existe une, une réponse dans le même langage naturel. La question sera traitée afin d’en extraire les informations utiles et ces dernières seront ensuite confrontées à une base de données dont l’architecture sera l’objet d’une étude détaillée. Les informations extraites de cette base de données seront ensuite reformulées en langage naturel. Le domaine d’application sera celui des livres et/ou des films. Ce mémoire mêlera donc ingénierie linguistique et bases de données.

\newpage
\section{Bibliographie}
\label{sec:bibliography}
\nocite{*}
\printbibliography


\end{document}


% LocalWords pour ispell
% LocalWords:  SQL Structured Query Language non-informaticien ciblé Eliza NLTK
% LocalWords:  humains-ordinateurs weizenbaum eliza Weizenbaum l'usabilité sql
% LocalWords:  Turing turing computing answering incrémentalement L'Internet
% LocalWords:  Movie DataBase collaboratifs Implémentation L'implémentation liu
% LocalWords:  toolkit ré-implémenter OpenCalais l'implémentation open-source
% LocalWords:  DB-Main d'implémentation bibliography hainaut jurafsky katz role
% LocalWords:  exploiting soderland learning appelt cardie empirical huffman
% LocalWords:  natural external ravichandran reder strategy lutz programming
% LocalWords:  learnpythonthehardway nlpwithpython head deitel Samsonova owda
% LocalWords:  waltz english sneiders automated frank constructing
% LocalWords:  androutsopoulos
